{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "incorporated-immune",
   "metadata": {},
   "source": [
    "## Notes\n",
    "#### In Pandas\n",
    "```\n",
    "df_sale.shape, df_resb.shape, df_parc.shape, look.shape\n",
    "((351067, 24), (181510, 50), (205199, 82), (1208, 3))\n",
    "```\n",
    "\n",
    "#### Merged Data Frame\n",
    "```\n",
    "# doing a chained merge of the three data frames on the 'Major' and 'Minor' columns\n",
    "df = pd.merge(pd.merge(df_sale, df_parc, on=['Major', 'Minor']), df_resb, on=['Major', 'Minor'])\n",
    "```\n",
    "\n",
    "```\n",
    "df.shape\n",
    "(251300, 151)\n",
    "```\n",
    "\n",
    "## In SQL Data Frame\n",
    "#### Tables\n",
    "```\n",
    "('SALES',), ('RESB',), ('PARC',)\n",
    "``` \n",
    "#### Data Frame Shape After Join\n",
    "```\n",
    "q = \"\"\"SELECT*FROM SALES AS SA\n",
    "       JOIN PARC AS PA\n",
    "       ON SA.Major = PA.Major\n",
    "       AND SA.Minor = PA.Minor\n",
    "       JOIN RESB AS RE\n",
    "       ON PA.Major = RE.Major\n",
    "       AND PA.Minor = RE.Minor\n",
    "       \"\"\"\n",
    "df = pd.DataFrame(fn.fetch(cur, q))\n",
    "df.columns = [i[0] for i in cur.description]\n",
    "```\n",
    "\n",
    "```\n",
    "df.shape\n",
    "(251300, 156)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-consortium",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "1. Pathing issues in the repo regarding the function.py module, DB_Creator notebook, KingDB.db file. Things break if the files are not in the same directory as the main notebook. What are the fixes?\n",
    "2. I placed a `.gitignore` file in the `/notebooks/exploratory` directory because the KingDB.db file is 176mb. Is it acceptable to have multiple .gitignore file in the repo? How do you deal with the pathing issues if you only have one `.gitignore` in the maid directory? On a side note, if your data files are large, how do you deal with that on github?\n",
    "3. Drop rows with null ZipCodes? It's 18% of the data. Categorical, Right? 106 uniques will add a lot of columns.\n",
    "4. Mean sale price of null zips is \\$117,000 dollars higher. Run a t-test on null zips and zips? Do we need to?\n",
    "5. Better way to clean the zips.\n",
    "6. Dollar sign in markdown.\n",
    "7. Code around `df.isna().sum()` so is only prints out columns with with nulls.\n",
    "8. The Ho for the betas in statsmodels ols is that they are not statistically significant, so we want p < alpha to reject the null hypothesis. Right?\n",
    "9. More statistically significant betas are better than a higher r^2, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-creation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
